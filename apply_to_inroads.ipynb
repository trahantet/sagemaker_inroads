{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.14.42)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.42 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.42)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.42->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.42->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "from predict_demo import model_fn\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "\n",
    "# !pip install gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.cluster import KMeans;\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10061, 302)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "object = s3.get_object(Bucket='inroads-test-bucket1',Key='data/Vectorized/inroads_vectorized.csv')\n",
    "inroads_vectorized = pd.read_csv(io.BytesIO(object['Body'].read()), encoding='utf8', index_col=0)\n",
    "\n",
    "inroads_vectorized=inroads_vectorized.rename(columns = {'tokens':'token'})\n",
    "\n",
    "inroads_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 302)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "object = s3.get_object(Bucket='inroads-test-bucket1',Key='data/Vectorized/old_vectorized.csv')\n",
    "old_vectorized = pd.read_csv(io.BytesIO(object['Body'].read()), encoding='utf8', index_col=0)\n",
    "\n",
    "old_vectorized.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_vocab = list()\n",
    "\n",
    "for i in range(0,len(old_vectorized)):\n",
    "    test = old_vectorized.iloc[i].token\n",
    "    old_vocab.append(test)\n",
    "\n",
    "old_vocab_df = pd.DataFrame(old_vocab, columns=[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_vectors_2 = list()\n",
    "\n",
    "for i in range(0,len(old_vectorized)):\n",
    "    test = old_vectorized.iloc[i, 2:].values\n",
    "    old_vectors_2.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_array = np.array(old_vectors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009340</td>\n",
       "      <td>-0.011540</td>\n",
       "      <td>-0.005011</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>-0.070042</td>\n",
       "      <td>-0.022673</td>\n",
       "      <td>0.035479</td>\n",
       "      <td>-0.033519</td>\n",
       "      <td>0.038251</td>\n",
       "      <td>0.045745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027858</td>\n",
       "      <td>0.024611</td>\n",
       "      <td>-0.013685</td>\n",
       "      <td>0.042488</td>\n",
       "      <td>0.054621</td>\n",
       "      <td>-0.036383</td>\n",
       "      <td>0.018394</td>\n",
       "      <td>-0.045638</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>-0.052491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.073121</td>\n",
       "      <td>-0.047603</td>\n",
       "      <td>0.091147</td>\n",
       "      <td>0.162190</td>\n",
       "      <td>-0.052149</td>\n",
       "      <td>-0.108441</td>\n",
       "      <td>-0.028311</td>\n",
       "      <td>-0.041613</td>\n",
       "      <td>-0.026646</td>\n",
       "      <td>-0.015232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018856</td>\n",
       "      <td>0.007211</td>\n",
       "      <td>-0.080637</td>\n",
       "      <td>0.157568</td>\n",
       "      <td>-0.035902</td>\n",
       "      <td>-0.001056</td>\n",
       "      <td>-0.014947</td>\n",
       "      <td>-0.114950</td>\n",
       "      <td>-0.121481</td>\n",
       "      <td>0.031619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013254</td>\n",
       "      <td>0.050222</td>\n",
       "      <td>-0.089445</td>\n",
       "      <td>0.083483</td>\n",
       "      <td>-0.044747</td>\n",
       "      <td>-0.065899</td>\n",
       "      <td>0.019941</td>\n",
       "      <td>-0.052136</td>\n",
       "      <td>0.037055</td>\n",
       "      <td>-0.078439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043838</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>-0.050873</td>\n",
       "      <td>-0.012946</td>\n",
       "      <td>-0.007152</td>\n",
       "      <td>0.148603</td>\n",
       "      <td>0.109223</td>\n",
       "      <td>-0.019303</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>0.042774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017232</td>\n",
       "      <td>-0.138262</td>\n",
       "      <td>-0.069550</td>\n",
       "      <td>0.161501</td>\n",
       "      <td>-0.024385</td>\n",
       "      <td>-0.121781</td>\n",
       "      <td>-0.035268</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>0.047652</td>\n",
       "      <td>-0.019447</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027821</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>-0.028523</td>\n",
       "      <td>0.028286</td>\n",
       "      <td>-0.049850</td>\n",
       "      <td>-0.049433</td>\n",
       "      <td>0.133848</td>\n",
       "      <td>0.008867</td>\n",
       "      <td>-0.076711</td>\n",
       "      <td>0.042498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.056970</td>\n",
       "      <td>0.020302</td>\n",
       "      <td>-0.024677</td>\n",
       "      <td>-0.048865</td>\n",
       "      <td>0.064803</td>\n",
       "      <td>-0.033035</td>\n",
       "      <td>-0.029016</td>\n",
       "      <td>-0.020143</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.015680</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071911</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>0.023876</td>\n",
       "      <td>0.077053</td>\n",
       "      <td>0.024279</td>\n",
       "      <td>-0.043584</td>\n",
       "      <td>-0.053606</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.018627</td>\n",
       "      <td>-0.046889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.009340 -0.011540 -0.005011  0.170543 -0.070042 -0.022673  0.035479   \n",
       "1  0.073121 -0.047603  0.091147  0.162190 -0.052149 -0.108441 -0.028311   \n",
       "2  0.013254  0.050222 -0.089445  0.083483 -0.044747 -0.065899  0.019941   \n",
       "3  0.017232 -0.138262 -0.069550  0.161501 -0.024385 -0.121781 -0.035268   \n",
       "4 -0.056970  0.020302 -0.024677 -0.048865  0.064803 -0.033035 -0.029016   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0 -0.033519  0.038251  0.045745  ...  0.027858  0.024611 -0.013685  0.042488   \n",
       "1 -0.041613 -0.026646 -0.015232  ...  0.018856  0.007211 -0.080637  0.157568   \n",
       "2 -0.052136  0.037055 -0.078439  ...  0.043838  0.002926 -0.050873 -0.012946   \n",
       "3  0.007963  0.047652 -0.019447  ...  0.027821  0.020316 -0.028523  0.028286   \n",
       "4 -0.020143  0.038997  0.015680  ... -0.071911 -0.002086  0.023876  0.077053   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0  0.054621 -0.036383  0.018394 -0.045638  0.025203 -0.052491  \n",
       "1 -0.035902 -0.001056 -0.014947 -0.114950 -0.121481  0.031619  \n",
       "2 -0.007152  0.148603  0.109223 -0.019303  0.029999  0.042774  \n",
       "3 -0.049850 -0.049433  0.133848  0.008867 -0.076711  0.042498  \n",
       "4  0.024279 -0.043584 -0.053606  0.007344  0.018627 -0.046889  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_vectors_df_2 = old_vectorized.drop(['token','vector'], axis=1)\n",
    "old_vectors_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "new text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of just tokens\n",
    "inroads_vocab = list()\n",
    "\n",
    "for i in range(0,len(inroads_vectorized)):\n",
    "    test = inroads_vectorized.iloc[i].token\n",
    "    inroads_vocab.append(test)\n",
    "\n",
    "inroads_vocab_df = pd.DataFrame(inroads_vocab, columns=[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of arrays of vectors\n",
    "inroads_vectors_2 = list()\n",
    "\n",
    "for i in range(0,len(inroads_vectorized)):\n",
    "    test = inroads_vectorized.iloc[i, 2:].values\n",
    "    inroads_vectors_2.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## formatted as numpy array\n",
    "import numpy as np\n",
    "inroads_array = np.array(inroads_vectors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188549</td>\n",
       "      <td>-0.051055</td>\n",
       "      <td>-0.051035</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>-0.108756</td>\n",
       "      <td>-0.054335</td>\n",
       "      <td>-0.003939</td>\n",
       "      <td>0.021723</td>\n",
       "      <td>-0.048769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067170</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.027066</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>-0.076336</td>\n",
       "      <td>0.020410</td>\n",
       "      <td>0.032563</td>\n",
       "      <td>-0.045787</td>\n",
       "      <td>-0.077532</td>\n",
       "      <td>-0.084312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.089151</td>\n",
       "      <td>-0.032444</td>\n",
       "      <td>0.066067</td>\n",
       "      <td>-0.083048</td>\n",
       "      <td>-0.025339</td>\n",
       "      <td>-0.115493</td>\n",
       "      <td>-0.082126</td>\n",
       "      <td>-0.015637</td>\n",
       "      <td>0.010993</td>\n",
       "      <td>-0.020402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031248</td>\n",
       "      <td>0.035671</td>\n",
       "      <td>0.022658</td>\n",
       "      <td>0.047292</td>\n",
       "      <td>-0.071116</td>\n",
       "      <td>-0.075786</td>\n",
       "      <td>0.015880</td>\n",
       "      <td>0.021262</td>\n",
       "      <td>-0.051069</td>\n",
       "      <td>-0.082306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080989</td>\n",
       "      <td>0.071457</td>\n",
       "      <td>-0.036697</td>\n",
       "      <td>0.051603</td>\n",
       "      <td>-0.098144</td>\n",
       "      <td>-0.004233</td>\n",
       "      <td>0.047631</td>\n",
       "      <td>0.025854</td>\n",
       "      <td>-0.024231</td>\n",
       "      <td>-0.023942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020227</td>\n",
       "      <td>0.035703</td>\n",
       "      <td>-0.040952</td>\n",
       "      <td>-0.026335</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.001704</td>\n",
       "      <td>0.098474</td>\n",
       "      <td>-0.053931</td>\n",
       "      <td>-0.007621</td>\n",
       "      <td>0.002607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048181</td>\n",
       "      <td>-0.024815</td>\n",
       "      <td>-0.042576</td>\n",
       "      <td>0.044887</td>\n",
       "      <td>-0.072843</td>\n",
       "      <td>-0.014483</td>\n",
       "      <td>-0.092501</td>\n",
       "      <td>-0.036309</td>\n",
       "      <td>-0.056641</td>\n",
       "      <td>-0.054676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>-0.002167</td>\n",
       "      <td>0.062039</td>\n",
       "      <td>0.115820</td>\n",
       "      <td>0.100294</td>\n",
       "      <td>0.055571</td>\n",
       "      <td>0.046550</td>\n",
       "      <td>0.041450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002084</td>\n",
       "      <td>0.084489</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.073587</td>\n",
       "      <td>-0.098434</td>\n",
       "      <td>-0.009841</td>\n",
       "      <td>-0.012736</td>\n",
       "      <td>-0.084855</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>-0.003929</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072306</td>\n",
       "      <td>-0.008926</td>\n",
       "      <td>-0.072427</td>\n",
       "      <td>-0.022924</td>\n",
       "      <td>-0.045194</td>\n",
       "      <td>-0.044142</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.026820</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>-0.025351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.188549 -0.051055 -0.051035  0.012129  0.018650 -0.108756 -0.054335   \n",
       "1 -0.089151 -0.032444  0.066067 -0.083048 -0.025339 -0.115493 -0.082126   \n",
       "2  0.080989  0.071457 -0.036697  0.051603 -0.098144 -0.004233  0.047631   \n",
       "3  0.048181 -0.024815 -0.042576  0.044887 -0.072843 -0.014483 -0.092501   \n",
       "4 -0.002084  0.084489  0.014706  0.073587 -0.098434 -0.009841 -0.012736   \n",
       "\n",
       "          7         8         9  ...       290       291       292       293  \\\n",
       "0 -0.003939  0.021723 -0.048769  ...  0.067170  0.014436  0.027066 -0.011628   \n",
       "1 -0.015637  0.010993 -0.020402  ... -0.031248  0.035671  0.022658  0.047292   \n",
       "2  0.025854 -0.024231 -0.023942  ... -0.020227  0.035703 -0.040952 -0.026335   \n",
       "3 -0.036309 -0.056641 -0.054676  ...  0.001294 -0.023781 -0.000153 -0.002167   \n",
       "4 -0.084855  0.008198 -0.003929  ...  0.072306 -0.008926 -0.072427 -0.022924   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.076336  0.020410  0.032563 -0.045787 -0.077532 -0.084312  \n",
       "1 -0.071116 -0.075786  0.015880  0.021262 -0.051069 -0.082306  \n",
       "2  0.001954  0.001704  0.098474 -0.053931 -0.007621  0.002607  \n",
       "3  0.062039  0.115820  0.100294  0.055571  0.046550  0.041450  \n",
       "4 -0.045194 -0.044142  0.019417  0.026820  0.013483 -0.025351  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## vectors only as df\n",
    "inroads_vectors_df_2 = inroads_vectorized.drop(['token','vector'], axis=1)\n",
    "inroads_vectors_df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping and loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sagemaker.sklearn.estimator import SKLearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=9, random_state=12345)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(9, random_state=12345)\n",
    "kmeans.fit(old_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the popular python library `joblib`, we can store and load our sklearn based models conveniently and quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inroads_model/kmeans_inroads.joblib']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(kmeans, 'inroads_model/kmeans_inroads.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading the model\n",
    "clusterer = load('inroads_model/kmeans_inroads.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00911223, -0.01475857,  0.02156253, ..., -0.01086714,\n",
       "        -0.02190037,  0.00932974],\n",
       "       [-0.01985547,  0.00391338,  0.01887953, ...,  0.01553798,\n",
       "        -0.00253671,  0.01605074],\n",
       "       [-0.00991414, -0.03176413, -0.01107653, ..., -0.03559942,\n",
       "        -0.0064654 ,  0.00151505],\n",
       "       ...,\n",
       "       [-0.01213695,  0.02188849, -0.0053943 , ..., -0.01972915,\n",
       "        -0.01170868,  0.01229602],\n",
       "       [ 0.03164612,  0.00056793,  0.00555031, ...,  0.00383961,\n",
       "         0.01936551,  0.00123629],\n",
       "       [-0.02034095, -0.00437334, -0.02058369, ..., -0.01609   ,\n",
       "        -0.03461457,  0.02567087]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00911223, -0.01475857,  0.02156253, ..., -0.01086714,\n",
       "        -0.02190037,  0.00932974],\n",
       "       [-0.01985547,  0.00391338,  0.01887953, ...,  0.01553798,\n",
       "        -0.00253671,  0.01605074],\n",
       "       [-0.00991414, -0.03176413, -0.01107653, ..., -0.03559942,\n",
       "        -0.0064654 ,  0.00151505],\n",
       "       ...,\n",
       "       [-0.01213695,  0.02188849, -0.0053943 , ..., -0.01972915,\n",
       "        -0.01170868,  0.01229602],\n",
       "       [ 0.03164612,  0.00056793,  0.00555031, ...,  0.00383961,\n",
       "         0.01936551,  0.00123629],\n",
       "       [-0.02034095, -0.00437334, -0.02058369, ..., -0.01609   ,\n",
       "        -0.03461457,  0.02567087]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-068949824886\n"
     ]
    }
   ],
   "source": [
    "bucket_name = bucket\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## not sure if this actually works so keeping it out for now\n",
    "#!tar -czf model.tar.gz demo_model/kmeans_demo.joblib\n",
    "#!aws s3 cp model.tar.gz s3://sagemaker-us-east-1-068949824886/model/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key = 'demo_model/kmeans_demo.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3 = boto3.resource('s3')\n",
    "#s3.meta.client.upload_file(key, bucket_name, 'model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing I always do is go to my AWS console and double-check that it really is there and it looks as you expect it to look. This has the double effect of letting me know I did something right and reinforcing my confidence in my AWS skill. \n",
    "\n",
    "For the sake of coherency and good practice, let's upload the data there too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_vectors_df_2.to_csv('inroads_model/inroads_data_test.csv', columns = old_vectors_df_2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'inroads_model/inroads_data_test.csv'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'data'\n",
    "\n",
    "# upload all data to S3\n",
    "s3_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket_name, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-068949824886'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/inroads_data_test.csv\n",
      "data/iris_data_test.csv\n",
      "data/sagemaker-scikit-learn-2020-08-26-13-55-58-101/debug-output/training_job_end.ts\n",
      "data/sagemaker-scikit-learn-2020-08-26-13-55-58-101/output/model.tar.gz\n",
      "model/model.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-26-13-55-58-101/source/sourcedir.tar.gz\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# also, here's code to use if you want to programmatically check that your data has been uploaded successfully\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important thing is that the model will be saved via joblib (we specified this at the end of the `__main__` function in the training script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPLOYING an already trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use an already pretrained model in AWS using SKLearn**Model** rather than just SKLearn. \n",
    "\n",
    "I'd previously saved the model artefacts as a joblib file, however the default files expected tend to be tar.gz files so AWS will have no problem recognising that kind of file. \n",
    "\n",
    "Two cells down I've provided the URL of my model's parameters and then I've instantiated the enpoint. \n",
    "When doing so, I am effectively telling AWS to get the artefacts from S3 and the instructions on how to use them from my `predict_demo.py` file (located in the source_dir). \n",
    "\n",
    "Now when this endpoint is deployed, it will always know to follow the instructions in the predict file, even when accessed via Lambda function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# the predictor endpoint expects something stored in an S3 bucket\\n# here I've just copied the url to my model artefacts from the AWS console\\nmodel_key = 'model/model.tar.gz' \\ndata_location = 's3://{}/{}'.format(bucket_name, model_key) \\n\\nmodel = SKLearnModel(model_data=model_url, # pointing to the model artefacts - our learned weights and coeffs\\n                     role = role, # using the specified ARN\\n                     framework_version='0.4.0', \\n                     entry_point='predict_demo.py', # which file to go to to find the respective functions\\n                     source_dir='demo_model/train') # directory to access\\n#                      predictor_cls=StringPredictor) \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# the predictor endpoint expects something stored in an S3 bucket\n",
    "# here I've just copied the url to my model artefacts from the AWS console\n",
    "model_key = 'model/model.tar.gz' \n",
    "data_location = 's3://{}/{}'.format(bucket_name, model_key) \n",
    "\n",
    "model = SKLearnModel(model_data=model_url, # pointing to the model artefacts - our learned weights and coeffs\n",
    "                     role = role, # using the specified ARN\n",
    "                     framework_version='0.4.0', \n",
    "                     entry_point='predict_demo.py', # which file to go to to find the respective functions\n",
    "                     source_dir='demo_model/train') # directory to access\n",
    "#                      predictor_cls=StringPredictor) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when using deploy AWS will look to find our model using `model_fn`; the entry point is the same as it was for when we trained \n",
    "# the estimator\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "#Uncomment the 3 lines below when we'll be using a string based predictor. Atm this kmeans model is just being used with the iris set\n",
    "\n",
    "# class StringPredictor(RealTimePredictor):\n",
    "#     def __init__(self, endpoint_name, sagemaker_session):\n",
    "#         super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL:  Training and saving an AWS style estimator\n",
    "Although not necessary for this project, it's still handy to know, especially if you have to train a model on a large amount of data or require GPUs. \n",
    "\n",
    "For deployment purposes we need the AWS SKLearn Estimator object. This acts as a dockerised container that allows AWS to interact with our sklearn model. I'll be training the AWS model below. I've written a training script in demo_model/train/train.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "train_channel = sagemaker.session.s3_input(s3_data, content_type='text/csv')\n",
    "data_channels = {'train': train_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-26 15:00:26 Starting - Starting the training job...\n",
      "2020-08-26 15:00:28 Starting - Launching requested ML instances.........\n",
      "2020-08-26 15:02:13 Starting - Preparing the instances for training......\n",
      "2020-08-26 15:03:18 Downloading - Downloading input data...\n",
      "2020-08-26 15:03:56 Training - Downloading the training image.....\u001b[34m2020-08-26 15:04:29,173 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-08-26 15:04:29,175 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 15:04:29,191 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-26 15:04:29,551 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 15:04:29,801 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 15:04:29,814 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 15:04:29,827 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-08-26-15-00-25-570\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-068949824886/sagemaker-scikit-learn-2020-08-26-15-00-25-570/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-068949824886/sagemaker-scikit-learn-2020-08-26-15-00-25-570/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-08-26-15-00-25-570\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-068949824886/sagemaker-scikit-learn-2020-08-26-15-00-25-570/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-08-26 15:04:33,406 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-08-26 15:04:41 Uploading - Uploading generated training model\n",
      "2020-08-26 15:04:41 Completed - Training job completed\n",
      "Training seconds: 83\n",
      "Billable seconds: 83\n",
      "CPU times: user 573 ms, sys: 16.4 ms, total: 589 ms\n",
      "Wall time: 4min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train your estimator on S3 training data\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket_name, prefix)\n",
    "\n",
    "estimator = SKLearn(entry_point='train.py',     # name of the training script AWS should access\n",
    "                    source_dir = 'inroads_model/train', # dir with training script\n",
    "                    role=role,   # the role we stated higher up in the nb\n",
    "                    train_instance_count=1,\n",
    "                    framework_version=\"0.23-1\",  # no need to change this\n",
    "                    train_instance_type='ml.m4.xlarge' ,  # no need to change this, unless you're using pytorch models OR want to include GP\n",
    "                    output_path = output_path,  # no need to change this, unless you want a different output location for the file\n",
    "                    sagemaker_session = sagemaker_session\n",
    "#                     hyperparameters = {\n",
    "#                                        'n_clusters':4,\n",
    "#                                         }\n",
    "                   )\n",
    "\n",
    "estimator.fit(data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "Using already existing model: sagemaker-scikit-learn-2020-08-26-15-00-25-570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "## if endopoint already created\n",
    "from sagemaker.amazon.kmeans import KMeans, KMeansPredictor\n",
    "predictor = KMeansPredictor('sagemaker-scikit-learn-2020-08-26-15-00-25-570')\n",
    "test = inroads_array\n",
    "test = test.astype(\"float32\")\n",
    "test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#otherwise\n",
    "\n",
    "test =inroads_vectors_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10061"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END THE SESSION; DELETE THE BUCKET AND ENDPOINT\n",
    "Uncomment the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "delete_endpoint() missing 1 required positional argument: 'endpoint_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5de3489be4c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# bucket_to_delete = boto3.resource('s3').Bucket(bucket)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# bucket_to_delete.objects.all().delete()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: delete_endpoint() missing 1 required positional argument: 'endpoint_name'"
     ]
    }
   ],
   "source": [
    "#sagemainroads_vectors_df_2endpoint()\n",
    "# bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "# bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-scikit-learn-2020-08-26-13-55-58-101'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
