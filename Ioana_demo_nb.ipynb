{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-3.8.3-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.14.0)\n",
      "Collecting smart-open>=1.8.1\n",
      "  Downloading smart_open-2.1.0.tar.gz (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 77.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.14.42)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.42 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.42)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.42->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.42->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-2.1.0-py3-none-any.whl size=110317 sha256=e35c3849347923ddb674bae565a79d3ed42b34b8824dfb6b925d5c5e5c9af177\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/a4/9b/d5/85705a7ab783cd6f7bd718f01d3b1396272f30044e3c36401a\n",
      "Successfully built smart-open\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-3.8.3 smart-open-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "from predict_demo import model_fn\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "\n",
    "# !pip install gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.cluster import KMeans;\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example I'll be using a canonical dataset, since I don't have access to the original data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "iris_data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data_arr = iris_data.data\n",
    "iris_df = pd.DataFrame(iris_data_arr, columns = iris_data.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dumping and loading a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sagemaker.sklearn.estimator import SKLearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=3, random_state=12345)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(3, random_state=12345)\n",
    "kmeans.fit(iris_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the popular python library `joblib`, we can store and load our sklearn based models conveniently and quickly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['demo_model/kmeans_demo.joblib']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(kmeans, 'demo_model/kmeans_demo.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading the model\n",
    "clusterer = load('demo_model/kmeans_demo.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.85      , 3.07368421, 5.74210526, 2.07105263],\n",
       "       [5.006     , 3.428     , 1.462     , 0.246     ],\n",
       "       [5.9016129 , 2.7483871 , 4.39354839, 1.43387097]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.85      , 3.07368421, 5.74210526, 2.07105263],\n",
       "       [5.006     , 3.428     , 1.462     , 0.246     ],\n",
       "       [5.9016129 , 2.7483871 , 4.39354839, 1.43387097]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusterer.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-us-east-1-068949824886\n"
     ]
    }
   ],
   "source": [
    "bucket_name = bucket\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -czf model.tar.gz demo_model/kmeans_demo.joblib\n",
    "#!aws s3 cp model.tar.gz s3://sagemaker-us-east-1-068949824886/model/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key = 'demo_model/kmeans_demo.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3 = boto3.resource('s3')\n",
    "#s3.meta.client.upload_file(key, bucket_name, 'model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing I always do is go to my AWS console and double-check that it really is there and it looks as you expect it to look. This has the double effect of letting me know I did something right and reinforcing my confidence in my AWS skill. \n",
    "\n",
    "For the sake of coherency and good practice, let's upload the data there too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.to_csv('demo_model/iris_data_test.csv', columns = iris_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'demo_model/iris_data_test.csv'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'data'\n",
    "\n",
    "# upload all data to S3\n",
    "s3_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket_name, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/iris_data_test.csv\n",
      "data/sagemaker-scikit-learn-2020-08-25-21-16-17-191/debug-output/training_job_end.ts\n",
      "data/sagemaker-scikit-learn-2020-08-25-21-16-17-191/output/model.tar.gz\n",
      "data/sagemaker-scikit-learn-2020-08-25-22-29-42-180/debug-output/training_job_end.ts\n",
      "data/sagemaker-scikit-learn-2020-08-25-22-29-42-180/output/model.tar.gz\n",
      "model/model.tar.gz\n",
      "sagemaker-record-sets/KMeans-2020-08-18-19-06-57-355/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-18-19-06-57-355/matrix_0.pbr\n",
      "sagemaker-record-sets/KMeans-2020-08-20-18-55-16-937/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-20-18-55-16-937/matrix_0.pbr\n",
      "sagemaker-record-sets/KMeans-2020-08-20-19-47-24-707/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-20-19-47-24-707/matrix_0.pbr\n",
      "sagemaker-record-sets/KMeans-2020-08-20-20-20-55-551/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-20-20-20-55-551/matrix_0.pbr\n",
      "sagemaker-record-sets/KMeans-2020-08-20-23-18-50-847/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-20-23-18-50-847/matrix_0.pbr\n",
      "sagemaker-record-sets/KMeans-2020-08-20-23-21-41-365/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-20-23-21-41-365/matrix_0.pbr\n",
      "sagemaker-record-sets/KMeans-2020-08-24-00-14-13-881/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-24-00-14-13-881/matrix_0.pbr\n",
      "sagemaker-record-sets/KMeans-2020-08-24-18-04-10-103/.amazon.manifest\n",
      "sagemaker-record-sets/KMeans-2020-08-24-18-04-10-103/matrix_0.pbr\n",
      "sagemaker-record-sets/PCA-2020-08-18-17-25-33-288/.amazon.manifest\n",
      "sagemaker-record-sets/PCA-2020-08-18-17-25-33-288/matrix_0.pbr\n",
      "sagemaker-record-sets/PCA-2020-08-18-18-08-11-142/.amazon.manifest\n",
      "sagemaker-record-sets/PCA-2020-08-18-18-08-11-142/matrix_0.pbr\n",
      "sagemaker-record-sets/PCA-2020-08-18-18-47-44-194/.amazon.manifest\n",
      "sagemaker-record-sets/PCA-2020-08-18-18-47-44-194/matrix_0.pbr\n",
      "sagemaker-scikit-learn-2020-08-25-13-40-20-380/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-13-41-12-803/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-13-41-33-843/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-13-45-08-856/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-13-46-00-250/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-13-47-13-250/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-13-49-22-749/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-13-50-18-196/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-14-07-43-669/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-16-08-649/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-16-47-252/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-20-26-737/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-22-53-812/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-23-32-722/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-26-13-948/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-47-05-999/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-47-06-176/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-47-54-579/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-48-06-477/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-48-33-620/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-49-31-088/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-50-19-467/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-53-12-005/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-54-01-116/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-54-48-986/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-59-26-287/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-16-59-42-909/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-17-02-37-025/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-17-08-48-025/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-17-15-55-556/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-17-23-18-335/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-17-24-34-582/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-17-42-10-054/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-17-42-10-252/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-19-20-22-044/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-19-32-15-120/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-19-49-31-260/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-19-55-24-464/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-20-03-13-844/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-20-10-07-513/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-20-15-57-457/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-20-30-02-270/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-20-37-44-629/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-20-47-23-933/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-21-00-05-541/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-21-00-17-554/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-21-06-14-928/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-21-16-17-191/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-22-23-14-955/source/sourcedir.tar.gz\n",
      "sagemaker-scikit-learn-2020-08-25-22-29-42-180/source/sourcedir.tar.gz\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# also, here's code to use if you want to programmatically check that your data has been uploaded successfully\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model.\n",
      "Done loading model.\n"
     ]
    }
   ],
   "source": [
    "model_fn('model/model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "my_tar = tarfile.open('model.tar.gz')\n",
    "my_tar.extractall( './test') # specify which folder to extract to\n",
    "my_tar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important thing is that the model will be saved via joblib (we specified this at the end of the `__main__` function in the training script. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPLOYING an already trained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use an already pretrained model in AWS using SKLearn**Model** rather than just SKLearn. \n",
    "\n",
    "I'd previously saved the model artefacts as a joblib file, however the default files expected tend to be tar.gz files so AWS will have no problem recognising that kind of file. \n",
    "\n",
    "Two cells down I've provided the URL of my model's parameters and then I've instantiated the enpoint. \n",
    "When doing so, I am effectively telling AWS to get the artefacts from S3 and the instructions on how to use them from my `predict_demo.py` file (located in the source_dir). \n",
    "\n",
    "Now when this endpoint is deployed, it will always know to follow the instructions in the predict file, even when accessed via Lambda function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn import SKLearnModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# the predictor endpoint expects something stored in an S3 bucket\\n# here I've just copied the url to my model artefacts from the AWS console\\nmodel_key = 'model/model.tar.gz' \\ndata_location = 's3://{}/{}'.format(bucket_name, model_key) \\n\\nmodel = SKLearnModel(model_data=model_url, # pointing to the model artefacts - our learned weights and coeffs\\n                     role = role, # using the specified ARN\\n                     framework_version='0.4.0', \\n                     entry_point='predict_demo.py', # which file to go to to find the respective functions\\n                     source_dir='demo_model/train') # directory to access\\n#                      predictor_cls=StringPredictor) \""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''# the predictor endpoint expects something stored in an S3 bucket\n",
    "# here I've just copied the url to my model artefacts from the AWS console\n",
    "model_key = 'model/model.tar.gz' \n",
    "data_location = 's3://{}/{}'.format(bucket_name, model_key) \n",
    "\n",
    "model = SKLearnModel(model_data=model_url, # pointing to the model artefacts - our learned weights and coeffs\n",
    "                     role = role, # using the specified ARN\n",
    "                     framework_version='0.4.0', \n",
    "                     entry_point='predict_demo.py', # which file to go to to find the respective functions\n",
    "                     source_dir='demo_model/train') # directory to access\n",
    "#                      predictor_cls=StringPredictor) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when using deploy AWS will look to find our model using `model_fn`; the entry point is the same as it was for when we trained \n",
    "# the estimator\n",
    "from sagemaker.predictor import RealTimePredictor\n",
    "#Uncomment the 3 lines below when we'll be using a string based predictor. Atm this kmeans model is just being used with the iris set\n",
    "\n",
    "# class StringPredictor(RealTimePredictor):\n",
    "#     def __init__(self, endpoint_name, sagemaker_session):\n",
    "#         super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL:  Training and saving an AWS style estimator\n",
    "Although not necessary for this project, it's still handy to know, especially if you have to train a model on a large amount of data or require GPUs. \n",
    "\n",
    "For deployment purposes we need the AWS SKLearn Estimator object. This acts as a dockerised container that allows AWS to interact with our sklearn model. I'll be training the AWS model below. I've written a training script in demo_model/train/train.py. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "train_channel = sagemaker.session.s3_input(s3_data, content_type='text/csv')\n",
    "data_channels = {'train': train_channel}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-26 13:55:58 Starting - Starting the training job...\n",
      "2020-08-26 13:56:05 Starting - Launching requested ML instances......\n",
      "2020-08-26 13:57:19 Starting - Preparing the instances for training......\n",
      "2020-08-26 13:58:25 Downloading - Downloading input data...\n",
      "2020-08-26 13:58:40 Training - Downloading the training image.........\n",
      "2020-08-26 14:00:22 Uploading - Uploading generated training model\n",
      "2020-08-26 14:00:22 Completed - Training job completed\n",
      "\u001b[34m2020-08-26 14:00:10,188 sagemaker-training-toolkit INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2020-08-26 14:00:10,191 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 14:00:10,210 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-08-26 14:00:10,578 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 14:00:10,591 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 14:00:10,604 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2020-08-26 14:00:10,617 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"ContentType\": \"text/csv\",\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-scikit-learn-2020-08-26-13-55-58-101\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-068949824886/sagemaker-scikit-learn-2020-08-26-13-55-58-101/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-068949824886/sagemaker-scikit-learn-2020-08-26-13-55-58-101/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-scikit-learn-2020-08-26-13-55-58-101\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-068949824886/sagemaker-scikit-learn-2020-08-26-13-55-58-101/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python train.py\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34m2020-08-26 14:00:12,545 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "Training seconds: 117\n",
      "Billable seconds: 117\n",
      "CPU times: user 569 ms, sys: 25.1 ms, total: 594 ms\n",
      "Wall time: 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train your estimator on S3 training data\n",
    "\n",
    "output_path = 's3://{}/{}'.format(bucket_name, prefix)\n",
    "\n",
    "estimator = SKLearn(entry_point='train.py',     # name of the training script AWS should access\n",
    "                    source_dir = 'demo_model/train', # dir with training script\n",
    "                    role=role,   # the role we stated higher up in the nb\n",
    "                    train_instance_count=1,\n",
    "                    framework_version=\"0.23-1\",  # no need to change this\n",
    "                    train_instance_type='ml.m4.xlarge' ,  # no need to change this, unless you're using pytorch models OR want to include GP\n",
    "                    output_path = output_path,  # no need to change this, unless you want a different output location for the file\n",
    "                    sagemaker_session = sagemaker_session\n",
    "#                     hyperparameters = {\n",
    "#                                        'n_clusters':4,\n",
    "#                                         }\n",
    "                   )\n",
    "\n",
    "estimator.fit(data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = iris_df.sample(frac=0.25, replace=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 3, 0, 3, 2, 0, 0, 2, 3, 1, 1, 3, 3, 0, 3, 3, 3, 2, 3, 0, 0,\n",
       "       1, 3, 2, 1, 2, 1, 0, 2, 1, 0, 0, 3, 1, 2, 0, 3], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END THE SESSION; DELETE THE BUCKET AND ENDPOINT\n",
    "Uncomment the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "delete_endpoint() missing 1 required positional argument: 'endpoint_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5de3489be4c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# bucket_to_delete = boto3.resource('s3').Bucket(bucket)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# bucket_to_delete.objects.all().delete()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: delete_endpoint() missing 1 required positional argument: 'endpoint_name'"
     ]
    }
   ],
   "source": [
    "#sagemaker_session.delete_endpoint()\n",
    "# bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "# bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-scikit-learn-2020-08-26-13-55-58-101'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
