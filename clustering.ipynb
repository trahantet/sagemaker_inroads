{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.8.3)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (2.1.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (1.14.42)\n",
      "Requirement already satisfied: boto in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.42 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.42)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.42->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from botocore<1.18.0,>=1.17.42->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import io\n",
    "\n",
    "!pip install gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.cluster import KMeans;\n",
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10061, 302)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "object = s3.get_object(Bucket='inroads-test-bucket1',Key='data/Vectorized/inroads_vectorized.csv')\n",
    "inroads_vectorized = pd.read_csv(io.BytesIO(object['Body'].read()), encoding='utf8', index_col=0)\n",
    "\n",
    "inroads_vectorized=inroads_vectorized.rename(columns = {'tokens':'token'})\n",
    "\n",
    "inroads_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(941, 302)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "object = s3.get_object(Bucket='inroads-test-bucket1',Key='data/Vectorized/old_vectorized.csv')\n",
    "old_vectorized = pd.read_csv(io.BytesIO(object['Body'].read()), encoding='utf8', index_col=0)\n",
    "\n",
    "old_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['token', 'vector', '0', '1', '2', '3', '4', '5', '6', '7',\n",
       "       ...\n",
       "       '290', '291', '292', '293', '294', '295', '296', '297', '298', '299'],\n",
       "      dtype='object', length=302)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inroads_vectorized.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Convert(string): \n",
    "    li = list(string.split(\" \")) \n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_vocab = list()\n",
    "\n",
    "for i in range(0,len(old_vectorized)):\n",
    "    test = old_vectorized.iloc[i].token\n",
    "    old_vocab.append(test)\n",
    "\n",
    "old_vocab_df = pd.DataFrame(old_vocab, columns=[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_vectors_2 = list()\n",
    "\n",
    "for i in range(0,len(old_vectorized)):\n",
    "    test = old_vectorized.iloc[i].vector\n",
    "    test_2 = str(test)[1:-1] \n",
    "    test_2 = Convert(test_2)\n",
    "    while(\"\" in test_2) : \n",
    "        test_2.remove(\"\")\n",
    "    test_2 = list(map(lambda s: s.strip(), test_2))\n",
    "    test_2 = np.array(test_2)\n",
    "    old_vectors_2.append(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_array = np.array(old_vectors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of             0         1         2         3         4         5         6  \\\n",
       "0    0.009340 -0.011540 -0.005011  0.170543 -0.070042 -0.022673  0.035479   \n",
       "1    0.073121 -0.047603  0.091147  0.162190 -0.052149 -0.108441 -0.028311   \n",
       "2    0.013254  0.050222 -0.089445  0.083483 -0.044747 -0.065899  0.019941   \n",
       "3    0.017232 -0.138262 -0.069550  0.161501 -0.024385 -0.121781 -0.035268   \n",
       "4   -0.056970  0.020302 -0.024677 -0.048865  0.064803 -0.033035 -0.029016   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "936 -0.021196 -0.011311 -0.073023  0.030679  0.117935  0.040947  0.024909   \n",
       "937 -0.028905  0.093232 -0.058349 -0.013379 -0.086675  0.104365  0.064961   \n",
       "938 -0.074280  0.093354 -0.145046  0.006174  0.000712  0.073791  0.088202   \n",
       "939 -0.045976 -0.006391 -0.056196 -0.057425 -0.018857 -0.025275  0.079501   \n",
       "940  0.014605  0.167768 -0.082776 -0.017683 -0.045675  0.065280  0.051255   \n",
       "\n",
       "            7         8         9  ...       290       291       292  \\\n",
       "0   -0.033519  0.038251  0.045745  ...  0.027858  0.024611 -0.013685   \n",
       "1   -0.041613 -0.026646 -0.015232  ...  0.018856  0.007211 -0.080637   \n",
       "2   -0.052136  0.037055 -0.078439  ...  0.043838  0.002926 -0.050873   \n",
       "3    0.007963  0.047652 -0.019447  ...  0.027821  0.020316 -0.028523   \n",
       "4   -0.020143  0.038997  0.015680  ... -0.071911 -0.002086  0.023876   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "936  0.073402  0.039913  0.030451  ... -0.079502  0.096267  0.060664   \n",
       "937  0.024115  0.153662  0.029945  ...  0.079233 -0.081211 -0.045705   \n",
       "938  0.058804  0.021020  0.019840  ... -0.028003 -0.029557 -0.022236   \n",
       "939  0.044921  0.043905  0.030954  ...  0.089390  0.021395  0.031801   \n",
       "940 -0.045690  0.037330  0.074602  ... -0.044892 -0.049401  0.061406   \n",
       "\n",
       "          293       294       295       296       297       298       299  \n",
       "0    0.042488  0.054621 -0.036383  0.018394 -0.045638  0.025203 -0.052491  \n",
       "1    0.157568 -0.035902 -0.001056 -0.014947 -0.114950 -0.121481  0.031619  \n",
       "2   -0.012946 -0.007152  0.148603  0.109223 -0.019303  0.029999  0.042774  \n",
       "3    0.028286 -0.049850 -0.049433  0.133848  0.008867 -0.076711  0.042498  \n",
       "4    0.077053  0.024279 -0.043584 -0.053606  0.007344  0.018627 -0.046889  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "936  0.034208 -0.119383  0.066091 -0.133915  0.001732 -0.072120  0.064670  \n",
       "937  0.038298 -0.008489 -0.004637 -0.072350  0.039764 -0.014958  0.071050  \n",
       "938 -0.088852 -0.003609  0.031037  0.097972  0.119025 -0.085960 -0.042356  \n",
       "939  0.014382 -0.027417  0.028251 -0.089081 -0.034247 -0.061705 -0.033233  \n",
       "940  0.076096  0.013065  0.041824 -0.068288 -0.040960 -0.040674  0.035157  \n",
       "\n",
       "[941 rows x 300 columns]>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_vectors_df_2 = old_vectorized.drop(['token','vector'], axis=1)\n",
    "old_vectors_df_2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inroads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inroads_vocab = list()\n",
    "\n",
    "for i in range(0,len(inroads_vectorized)):\n",
    "    test = inroads_vectorized.iloc[i].token\n",
    "    inroads_vocab.append(test)\n",
    "\n",
    "inroads_vocab_df = pd.DataFrame(inroads_vocab, columns=[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inroads_vectors_2 = list()\n",
    "\n",
    "for i in range(0,len(inroads_vectorized)):\n",
    "    test = inroads_vectorized.iloc[i].vector\n",
    "    test_2 = str(test)[1:-1] \n",
    "    test_2 = Convert(test_2)\n",
    "    while(\"\" in test_2) : \n",
    "        test_2.remove(\"\")\n",
    "    test_2 = list(map(lambda s: s.strip(), test_2))\n",
    "    test_2 = np.array(test_2)\n",
    "    inroads_vectors_2.append(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "inroads_array = np.array(inroads_vectors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               0         1         2         3         4         5         6  \\\n",
       "0      0.188549 -0.051055 -0.051035  0.012129  0.018650 -0.108756 -0.054335   \n",
       "1     -0.089151 -0.032444  0.066067 -0.083048 -0.025339 -0.115493 -0.082126   \n",
       "2      0.080989  0.071457 -0.036697  0.051603 -0.098144 -0.004233  0.047631   \n",
       "3      0.048181 -0.024815 -0.042576  0.044887 -0.072843 -0.014483 -0.092501   \n",
       "4     -0.002084  0.084489  0.014706  0.073587 -0.098434 -0.009841 -0.012736   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10056 -0.014218 -0.024084  0.081345 -0.069396 -0.051680  0.006385 -0.056575   \n",
       "10057 -0.073358 -0.063885  0.057451 -0.059011 -0.102870  0.027484 -0.090268   \n",
       "10058 -0.082558  0.043012 -0.118982 -0.168650  0.035012  0.004704  0.010404   \n",
       "10059  0.010403 -0.001597  0.022658  0.142871  0.002488 -0.039659 -0.024233   \n",
       "10060  0.013340  0.024281 -0.089154  0.055416  0.031318  0.012631  0.109731   \n",
       "\n",
       "              7         8         9  ...       290       291       292  \\\n",
       "0     -0.003939  0.021723 -0.048769  ...  0.067170  0.014436  0.027066   \n",
       "1     -0.015637  0.010993 -0.020402  ... -0.031248  0.035671  0.022658   \n",
       "2      0.025854 -0.024231 -0.023942  ... -0.020227  0.035703 -0.040952   \n",
       "3     -0.036309 -0.056641 -0.054676  ...  0.001294 -0.023781 -0.000153   \n",
       "4     -0.084855  0.008198 -0.003929  ...  0.072306 -0.008926 -0.072427   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10056  0.193053  0.073471  0.054874  ... -0.052560 -0.098588  0.010969   \n",
       "10057  0.049498  0.074800  0.087983  ... -0.018132 -0.060725 -0.017951   \n",
       "10058  0.037006 -0.035008  0.085903  ... -0.002580 -0.025475 -0.014083   \n",
       "10059  0.012931 -0.078566  0.044646  ...  0.044288 -0.061349  0.003900   \n",
       "10060  0.014341 -0.005156  0.061679  ...  0.068354 -0.119120  0.064430   \n",
       "\n",
       "            293       294       295       296       297       298       299  \n",
       "0     -0.011628 -0.076336  0.020410  0.032563 -0.045787 -0.077532 -0.084312  \n",
       "1      0.047292 -0.071116 -0.075786  0.015880  0.021262 -0.051069 -0.082306  \n",
       "2     -0.026335  0.001954  0.001704  0.098474 -0.053931 -0.007621  0.002607  \n",
       "3     -0.002167  0.062039  0.115820  0.100294  0.055571  0.046550  0.041450  \n",
       "4     -0.022924 -0.045194 -0.044142  0.019417  0.026820  0.013483 -0.025351  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "10056  0.000303  0.012525  0.024695 -0.099009 -0.039917 -0.073046 -0.057320  \n",
       "10057 -0.002820  0.020353  0.010160 -0.051351 -0.017208 -0.039342 -0.034791  \n",
       "10058 -0.033139  0.047937 -0.032920  0.019858 -0.015019  0.093141 -0.025104  \n",
       "10059 -0.058371 -0.064461 -0.049368 -0.036179 -0.029942  0.039247 -0.071742  \n",
       "10060 -0.006576 -0.002567 -0.020004  0.010457  0.000264  0.019231  0.082335  \n",
       "\n",
       "[10061 rows x 300 columns]>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inroads_vectors_df_2 = inroads_vectorized.drop(['token','vector'], axis=1)\n",
    "inroads_vectors_df_2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [old_vectorized, inroads_vectorized]\n",
    "\n",
    "combined_vectorized = pd.concat(frames)\n",
    "combined_vectorized = combined_vectorized.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vocab = list()\n",
    "\n",
    "for i in range(0,len(combined_vectorized)):\n",
    "    test = combined_vectorized.iloc[i].token\n",
    "    combined_vocab.append(test)\n",
    "\n",
    "combined_vocab_df = pd.DataFrame(combined_vocab, columns=[\"token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vectors_2 = list()\n",
    "\n",
    "for i in range(0,len(combined_vectorized)):\n",
    "    test = combined_vectorized.iloc[i].vector\n",
    "    test_2 = str(test)[1:-1] \n",
    "    test_2 = Convert(test_2)\n",
    "    while(\"\" in test_2) : \n",
    "        test_2.remove(\"\")\n",
    "    test_2 = list(map(lambda s: s.strip(), test_2))\n",
    "    test_2 = np.array(test_2)\n",
    "    combined_vectors_2.append(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "combined_array = np.array(combined_vectors_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               0         1         2         3         4         5         6  \\\n",
       "0      0.009340 -0.011540 -0.005011  0.170543 -0.070042 -0.022673  0.035479   \n",
       "1      0.073121 -0.047603  0.091147  0.162190 -0.052149 -0.108441 -0.028311   \n",
       "2      0.013254  0.050222 -0.089445  0.083483 -0.044747 -0.065899  0.019941   \n",
       "3      0.017232 -0.138262 -0.069550  0.161501 -0.024385 -0.121781 -0.035268   \n",
       "4     -0.056970  0.020302 -0.024677 -0.048865  0.064803 -0.033035 -0.029016   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10056 -0.014218 -0.024084  0.081345 -0.069396 -0.051680  0.006385 -0.056575   \n",
       "10057 -0.073358 -0.063885  0.057451 -0.059011 -0.102870  0.027484 -0.090268   \n",
       "10058 -0.082558  0.043012 -0.118982 -0.168650  0.035012  0.004704  0.010404   \n",
       "10059  0.010403 -0.001597  0.022658  0.142871  0.002488 -0.039659 -0.024233   \n",
       "10060  0.013340  0.024281 -0.089154  0.055416  0.031318  0.012631  0.109731   \n",
       "\n",
       "              7         8         9  ...       290       291       292  \\\n",
       "0     -0.033519  0.038251  0.045745  ...  0.027858  0.024611 -0.013685   \n",
       "1     -0.041613 -0.026646 -0.015232  ...  0.018856  0.007211 -0.080637   \n",
       "2     -0.052136  0.037055 -0.078439  ...  0.043838  0.002926 -0.050873   \n",
       "3      0.007963  0.047652 -0.019447  ...  0.027821  0.020316 -0.028523   \n",
       "4     -0.020143  0.038997  0.015680  ... -0.071911 -0.002086  0.023876   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "10056  0.193053  0.073471  0.054874  ... -0.052560 -0.098588  0.010969   \n",
       "10057  0.049498  0.074800  0.087983  ... -0.018132 -0.060725 -0.017951   \n",
       "10058  0.037006 -0.035008  0.085903  ... -0.002580 -0.025475 -0.014083   \n",
       "10059  0.012931 -0.078566  0.044646  ...  0.044288 -0.061349  0.003900   \n",
       "10060  0.014341 -0.005156  0.061679  ...  0.068354 -0.119120  0.064430   \n",
       "\n",
       "            293       294       295       296       297       298       299  \n",
       "0      0.042488  0.054621 -0.036383  0.018394 -0.045638  0.025203 -0.052491  \n",
       "1      0.157568 -0.035902 -0.001056 -0.014947 -0.114950 -0.121481  0.031619  \n",
       "2     -0.012946 -0.007152  0.148603  0.109223 -0.019303  0.029999  0.042774  \n",
       "3      0.028286 -0.049850 -0.049433  0.133848  0.008867 -0.076711  0.042498  \n",
       "4      0.077053  0.024279 -0.043584 -0.053606  0.007344  0.018627 -0.046889  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "10056  0.000303  0.012525  0.024695 -0.099009 -0.039917 -0.073046 -0.057320  \n",
       "10057 -0.002820  0.020353  0.010160 -0.051351 -0.017208 -0.039342 -0.034791  \n",
       "10058 -0.033139  0.047937 -0.032920  0.019858 -0.015019  0.093141 -0.025104  \n",
       "10059 -0.058371 -0.064461 -0.049368 -0.036179 -0.029942  0.039247 -0.071742  \n",
       "10060 -0.006576 -0.002567 -0.020004  0.010457  0.000264  0.019231  0.082335  \n",
       "\n",
       "[10146 rows x 300 columns]>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_vectors_df_2 = combined_vectorized.drop(['token','vector'], axis=1)\n",
    "combined_vectors_df_2.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_on_wordvecs(word_vectors, num_clusters):\n",
    "    # Initalize a k-means object and use it to extract centroids\n",
    "    kmeans_clustering = KMeans(n_clusters = num_clusters, init='k-means++', random_state = 1);\n",
    "    idx = kmeans_clustering.fit_predict(word_vectors);\n",
    "    \n",
    "    return kmeans_clustering, kmeans_clustering.cluster_centers_, idx;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_words(index2word, k, centers, wordvecs):\n",
    "    tree = KDTree(wordvecs);\n",
    "#Closest points for each Cluster center is used to query the closest 20 points to it.\n",
    "    closest_points = [tree.query(np.reshape(x, (1, -1)), k=k) for x in centers];\n",
    "    closest_words_idxs = [x[1] for x in closest_points];\n",
    "#Word Index is queried for each position in the above array, and added to a Dictionary.\n",
    "    closest_words = {};\n",
    "    for i in range(0, len(closest_words_idxs)):\n",
    "        closest_words['Cluster #' + str(i)] = [index2word[j] for j in closest_words_idxs[i][0]]\n",
    "#A DataFrame is generated from the dictionary.\n",
    "    df = pd.DataFrame(closest_words);\n",
    "    df.index = df.index+1\n",
    "    return df, tree;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmodel,centers,clusters = clustering_on_wordvecs(combined_vectors_2, 9);\n",
    "centroid_map = dict(zip(combined_vocab, clusters));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_cluster = {}\n",
    "\n",
    "for i in range(0, len(combined_vectors_2)):\n",
    "    word = combined_vocab[i]\n",
    "    temp = kmodel.predict(combined_vectors_2[i].reshape(1,-1))[0]\n",
    "    predicted_cluster.update({word:temp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstract': 1,\n",
       " 'absence': 1,\n",
       " 'abundance': 5,\n",
       " 'reality': 5,\n",
       " 'beautiful': 7,\n",
       " 'complexity': 5,\n",
       " 'creation': 5,\n",
       " 'finality': 1,\n",
       " 'truth': 2,\n",
       " 'burial': 8,\n",
       " 'life': 5,\n",
       " 'complicate': 5,\n",
       " 'natural': 5,\n",
       " 'peace': 6,\n",
       " 'universal': 1,\n",
       " 'work': 5,\n",
       " 'nuance': 5,\n",
       " 'complex': 5,\n",
       " 'vision': 5,\n",
       " 'security': 1,\n",
       " 'save': 1,\n",
       " 'live': 2,\n",
       " 'stable': 1,\n",
       " 'option': 1,\n",
       " 'limbo': 2,\n",
       " 'circle': 0,\n",
       " 'square': 7,\n",
       " 'triangle': 7,\n",
       " 'rectangle': 7,\n",
       " 'sphere': 5,\n",
       " 'blue': 7,\n",
       " 'color': 0,\n",
       " 'orange': 7,\n",
       " 'yellow': 7,\n",
       " 'green': 7,\n",
       " 'purple': 7,\n",
       " 'black': 5,\n",
       " 'white': 6,\n",
       " 'darkness': 7,\n",
       " 'light': 0,\n",
       " 'radiance': 7,\n",
       " 'actor': 4,\n",
       " 'entertainment': 0,\n",
       " 'music': 0,\n",
       " 'literature': 5,\n",
       " 'performance': 0,\n",
       " 'theater': 0,\n",
       " 'drama': 0,\n",
       " 'poetry': 0,\n",
       " 'artist': 4,\n",
       " 'band': 6,\n",
       " 'musical': 0,\n",
       " 'book': 0,\n",
       " 'film': 0,\n",
       " 'documentary': 0,\n",
       " 'misinformation': 2,\n",
       " 'advertisement': 0,\n",
       " 'radio': 0,\n",
       " 'silence': 2,\n",
       " 'media': 5,\n",
       " 'journalism': 0,\n",
       " 'social': 5,\n",
       " 'what': 5,\n",
       " 'billboard': 7,\n",
       " 'poster': 7,\n",
       " 'flyer': 7,\n",
       " 'talk': 2,\n",
       " 'show': 5,\n",
       " 'charity': 1,\n",
       " 'value': 5,\n",
       " 'community': 5,\n",
       " 'norms': 5,\n",
       " 'customs': 1,\n",
       " 'stigmatization': 8,\n",
       " 'ethics': 5,\n",
       " 'moral': 5,\n",
       " 'good': 1,\n",
       " 'morally': 1,\n",
       " 'morality': 5,\n",
       " 'stigma': 8,\n",
       " 'right': 1,\n",
       " 'correct': 1,\n",
       " 'wrong': 1,\n",
       " 'incorrect': 1,\n",
       " 'patriarchy': 5,\n",
       " 'judgement': 1,\n",
       " 'society': 5,\n",
       " 'dirty': 7,\n",
       " 'stigmatize': 1,\n",
       " 'shun': 1,\n",
       " 'cultural': 5,\n",
       " 'taboo': 2,\n",
       " 'normal': 8,\n",
       " 'sexism': 1,\n",
       " 'escape': 2,\n",
       " 'privilege': 1,\n",
       " 'adolescent': 8,\n",
       " 'adult': 8,\n",
       " 'baby': 8,\n",
       " 'child': 8,\n",
       " 'children': 8,\n",
       " 'teenager': 4,\n",
       " 'youth': 6,\n",
       " 'elders': 6,\n",
       " 'identity': 5,\n",
       " 'female': 8,\n",
       " 'woman': 2,\n",
       " 'male': 8,\n",
       " 'gender': 5,\n",
       " 'girl': 7,\n",
       " 'women': 5,\n",
       " 'people': 1,\n",
       " 'poverty': 5,\n",
       " 'poor': 1,\n",
       " 'affordable': 1,\n",
       " 'assets': 1,\n",
       " 'bill': 6,\n",
       " 'payment': 8,\n",
       " 'cost': 8,\n",
       " 'financial': 1,\n",
       " 'insurance': 1,\n",
       " 'money': 1,\n",
       " 'cash': 7,\n",
       " 'expense': 1,\n",
       " 'abortion': 8,\n",
       " 'fund': 6,\n",
       " 'access': 1,\n",
       " 'seeker': 4,\n",
       " 'coverage': 0,\n",
       " 'free': 1,\n",
       " 'profit': 1,\n",
       " 'urban': 6,\n",
       " 'rural': 6,\n",
       " 'address': 5,\n",
       " 'location': 5,\n",
       " 'africa': 5,\n",
       " 'asia': 6,\n",
       " 'north': 6,\n",
       " 'america': 6,\n",
       " 'europe': 6,\n",
       " 'south': 6,\n",
       " 'oceania': 6,\n",
       " 'latin': 5,\n",
       " 'caribbean': 5,\n",
       " 'middle': 6,\n",
       " 'east': 6,\n",
       " 'northern': 6,\n",
       " 'hemisphere': 6,\n",
       " 'southern': 6,\n",
       " 'global': 5,\n",
       " 'antarctica': 6,\n",
       " 'bridge': 5,\n",
       " 'city': 6,\n",
       " 'suburb': 7,\n",
       " 'town': 7,\n",
       " 'sidewalk': 7,\n",
       " 'migrant': 6,\n",
       " 'plantation': 6,\n",
       " 'barrio': 6,\n",
       " 'national': 6,\n",
       " 'bush': 6,\n",
       " 'forward': 5,\n",
       " 'close': 6,\n",
       " 'nearby': 7,\n",
       " 'home': 6,\n",
       " 'distance': 2,\n",
       " 'local': 6,\n",
       " 'abandon': 1,\n",
       " 'account': 5,\n",
       " 'narrative': 5,\n",
       " 'story': 0,\n",
       " 'airplane': 7,\n",
       " 'plane': 7,\n",
       " 'bicycle': 7,\n",
       " 'bike': 7,\n",
       " 'motorcycle': 7,\n",
       " 'subway': 7,\n",
       " 'train': 6,\n",
       " 'trolley': 7,\n",
       " 'automobile': 7,\n",
       " 'airport': 7,\n",
       " 'station': 6,\n",
       " 'stop': 7,\n",
       " 'boat': 7,\n",
       " 'ship': 7,\n",
       " 'birthday': 4,\n",
       " 'wait': 7,\n",
       " 'dream': 2,\n",
       " 'during': 6,\n",
       " 'sleep': 7,\n",
       " 'sure': 2,\n",
       " 'self': 5,\n",
       " 'manage': 1,\n",
       " 'balloon': 7,\n",
       " 'barrier': 1,\n",
       " 'challenge': 5,\n",
       " 'childcare': 8,\n",
       " 'patient': 8,\n",
       " 'confident': 2,\n",
       " 'convenience': 1,\n",
       " 'crisis': 2,\n",
       " 'urgency': 5,\n",
       " 'nightmare': 2,\n",
       " 'funeral': 4,\n",
       " 'lobby': 6,\n",
       " 'room': 7,\n",
       " 'motherhood': 5,\n",
       " 'pathway': 5,\n",
       " 'stress': 5,\n",
       " 'travel': 6,\n",
       " 'unintended': 8,\n",
       " 'pregnancy': 8,\n",
       " 'unwanted': 8,\n",
       " 'unplanned': 8,\n",
       " 'mother': 8,\n",
       " 'solution': 1,\n",
       " 'choice': 1,\n",
       " 'personal': 5,\n",
       " 'process': 5,\n",
       " 'hotel': 7,\n",
       " 'motel': 7,\n",
       " 'drive': 2,\n",
       " 'isolation': 5,\n",
       " 'plan': 6,\n",
       " 'responsibility': 1,\n",
       " 'information': 8,\n",
       " 'seek': 1,\n",
       " 'consequences': 5,\n",
       " 'need': 1,\n",
       " 'individual': 5,\n",
       " 'clandestine': 6,\n",
       " 'necessary': 1,\n",
       " 'dilemma': 5,\n",
       " 'alter': 1,\n",
       " 'champagne': 7,\n",
       " 'purpose': 5,\n",
       " 'legitimate': 1,\n",
       " 'opportunity': 1,\n",
       " 'wonderful': 2,\n",
       " 'quandary': 0,\n",
       " 'secret': 2,\n",
       " 'trajectory': 5,\n",
       " 'toilet': 7,\n",
       " 'garbage': 7,\n",
       " 'trash': 7,\n",
       " 'care': 8,\n",
       " 'effort': 1,\n",
       " 'privacy': 1,\n",
       " 'prostitution': 1,\n",
       " 'prostitute': 6,\n",
       " 'journey': 2,\n",
       " 'queue': 7,\n",
       " 'breast': 8,\n",
       " 'breath': 7,\n",
       " 'breathe': 7,\n",
       " 'aspiration': 1,\n",
       " 'body': 5,\n",
       " 'brain': 8,\n",
       " 'blind': 2,\n",
       " 'cheek': 7,\n",
       " 'pain': 8,\n",
       " 'physical': 8,\n",
       " 'face': 2,\n",
       " 'head': 7,\n",
       " 'feet': 7,\n",
       " 'legs': 7,\n",
       " 'hand': 7,\n",
       " 'stomach': 7,\n",
       " 'uterus': 8,\n",
       " 'womb': 2,\n",
       " 'cervix': 8,\n",
       " 'vagina': 8,\n",
       " 'abdomen': 7,\n",
       " 'heart': 2,\n",
       " 'tear': 7,\n",
       " 'blood': 7,\n",
       " 'nausea': 8,\n",
       " 'exhaustion': 2,\n",
       " 'clitoris': 8,\n",
       " 'vulva': 2,\n",
       " 'accept': 1,\n",
       " 'feel': 2,\n",
       " 'belong': 5,\n",
       " 'pretend': 7,\n",
       " 'admiration': 2,\n",
       " 'afraid': 2,\n",
       " 'fear': 2,\n",
       " 'worry': 2,\n",
       " 'terror': 2,\n",
       " 'anxiety': 2,\n",
       " 'agency': 5,\n",
       " 'determination': 5,\n",
       " 'anticipation': 2,\n",
       " 'eagerness': 2,\n",
       " 'appreciation': 5,\n",
       " 'gratitude': 2,\n",
       " 'goal': 5,\n",
       " 'wish': 2,\n",
       " 'assertive': 6,\n",
       " 'certain': 1,\n",
       " 'surprise': 2,\n",
       " 'horror': 2,\n",
       " 'avoidance': 8,\n",
       " 'aware': 1,\n",
       " 'awareness': 5,\n",
       " 'brave': 2,\n",
       " 'choose': 1,\n",
       " 'unclean': 2,\n",
       " 'smart': 2,\n",
       " 'intelligent': 2,\n",
       " 'conflict': 5,\n",
       " 'internal': 5,\n",
       " 'conscience': 1,\n",
       " 'content': 0,\n",
       " 'satisfy': 1,\n",
       " 'satisfaction': 8,\n",
       " 'conviction': 1,\n",
       " 'belief': 5,\n",
       " 'courage': 2,\n",
       " 'bravery': 4,\n",
       " 'cowardice': 2,\n",
       " 'mental': 8,\n",
       " 'illness': 8,\n",
       " 'decision': 1,\n",
       " 'desperation': 2,\n",
       " 'dignity': 1,\n",
       " 'emotions': 5,\n",
       " 'anger': 2,\n",
       " 'rage': 2,\n",
       " 'sadness': 2,\n",
       " 'sorrow': 2,\n",
       " 'grief': 2,\n",
       " 'depression': 8,\n",
       " 'happiness': 5,\n",
       " 'disgust': 2,\n",
       " 'shame': 2,\n",
       " 'envy': 2,\n",
       " 'love': 2,\n",
       " 'hatred': 2,\n",
       " 'pride': 2,\n",
       " 'empathy': 5,\n",
       " 'enjoyment': 1,\n",
       " 'emotional': 5,\n",
       " 'hopeful': 2,\n",
       " 'loss': 2,\n",
       " 'opinion': 1,\n",
       " 'regret': 2,\n",
       " 'relief': 6,\n",
       " 'struggle': 5,\n",
       " 'heartbreak': 2,\n",
       " 'secure': 1,\n",
       " 'safety': 8,\n",
       " 'positive': 5,\n",
       " 'negative': 1,\n",
       " 'alone': 2,\n",
       " 'pleasure': 2,\n",
       " 'frighten': 2,\n",
       " 'reason': 1,\n",
       " 'sovereignty': 1,\n",
       " 'over': 1,\n",
       " 'oneself': 2,\n",
       " 'power': 1,\n",
       " 'powerful': 1,\n",
       " 'confusion': 2,\n",
       " 'happy': 2,\n",
       " 'hope': 2,\n",
       " 'strength': 5,\n",
       " 'release': 6,\n",
       " 'vulnerable': 1,\n",
       " 'tension': 5,\n",
       " 'burst': 7,\n",
       " 'knowledge': 5,\n",
       " 'embarrass': 2,\n",
       " 'expose': 1,\n",
       " 'morale': 2,\n",
       " 'inspire': 0,\n",
       " 'overwhelm': 2,\n",
       " 'suffer': 2,\n",
       " 'scar': 2,\n",
       " 'memory': 2,\n",
       " 'abstinence': 8,\n",
       " 'sexual': 5,\n",
       " 'sexuality': 5,\n",
       " 'promiscuity': 8,\n",
       " 'loose': 7,\n",
       " 'bless': 2,\n",
       " 'atheism': 1,\n",
       " 'agnosticism': 2,\n",
       " 'christ': 2,\n",
       " 'buddha': 2,\n",
       " 'allah': 2,\n",
       " 'evil': 2,\n",
       " 'sinful': 1,\n",
       " 'faith': 5,\n",
       " 'immoral': 1,\n",
       " 'sinner': 2,\n",
       " 'vigil': 4,\n",
       " 'rosary': 7,\n",
       " 'righteousness': 2,\n",
       " 'academic': 5,\n",
       " 'academia': 5,\n",
       " 'classroom': 0,\n",
       " 'college': 6,\n",
       " 'university': 6,\n",
       " 'school': 6,\n",
       " 'education': 5,\n",
       " 'ambulance': 7,\n",
       " 'approval': 1,\n",
       " 'procedure': 8,\n",
       " 'authorization': 1,\n",
       " 'ministry': 6,\n",
       " 'health': 8,\n",
       " 'center': 6,\n",
       " 'facility': 6,\n",
       " 'clinic': 8,\n",
       " 'doctor': 8,\n",
       " 'provider': 8,\n",
       " 'nurse': 8,\n",
       " 'midwife': 8,\n",
       " 'worker': 6,\n",
       " 'eligibility': 8,\n",
       " 'hospital': 8,\n",
       " 'gynecologist': 4,\n",
       " 'obstetrician': 4,\n",
       " 'conscientious': 1,\n",
       " 'objection': 1,\n",
       " 'availability': 8,\n",
       " 'hotline': 6,\n",
       " 'professional': 5,\n",
       " 'healthcare': 8,\n",
       " 'referral': 8,\n",
       " 'doula': 0,\n",
       " 'pharmacist': 4,\n",
       " 'public': 1,\n",
       " 'sector': 6,\n",
       " 'private': 1,\n",
       " 'stock': 0,\n",
       " 'healer': 4,\n",
       " 'refusal': 1,\n",
       " 'practitioner': 0,\n",
       " 'drug': 8,\n",
       " 'shop': 7,\n",
       " 'chemist': 4,\n",
       " 'workers': 6,\n",
       " 'supplier': 6,\n",
       " 'standards': 1,\n",
       " 'guidelines': 1,\n",
       " 'army': 6,\n",
       " 'navy': 6,\n",
       " 'force': 1,\n",
       " 'marines': 4,\n",
       " 'military': 6,\n",
       " 'soldier': 6,\n",
       " 'organization': 6,\n",
       " 'association': 6,\n",
       " 'organizations': 5,\n",
       " 'foundation': 5,\n",
       " 'parenthood': 5,\n",
       " 'ipas': 4,\n",
       " 'inroads': 6,\n",
       " 'marie': 4,\n",
       " 'administer': 8,\n",
       " 'operation': 6,\n",
       " 'rescue': 2,\n",
       " 'world': 5,\n",
       " 'catholicism': 5,\n",
       " 'christianity': 5,\n",
       " 'hinduism': 0,\n",
       " 'buddhism': 5,\n",
       " 'jainism': 0,\n",
       " 'islam': 5,\n",
       " 'judaism': 5,\n",
       " 'religion': 5,\n",
       " 'jesus': 2,\n",
       " 'yhwh': 2,\n",
       " 'mohammed': 4,\n",
       " 'church': 6,\n",
       " 'synagogue': 7,\n",
       " 'temple': 6,\n",
       " 'mosque': 6,\n",
       " 'monastery': 7,\n",
       " 'devil': 2,\n",
       " 'extremism': 5,\n",
       " 'religious': 5,\n",
       " 'fundamentalism': 5,\n",
       " 'bible': 0,\n",
       " 'preacher': 4,\n",
       " 'satan': 2,\n",
       " 'scripture': 0,\n",
       " 'brother': 4,\n",
       " 'adoption': 8,\n",
       " 'father': 4,\n",
       " 'daughter': 4,\n",
       " 'sister': 4,\n",
       " 'grandmother': 7,\n",
       " 'grandfather': 4,\n",
       " 'grandchild': 4,\n",
       " 'uncle': 4,\n",
       " 'aunt': 7,\n",
       " 'auntie': 7,\n",
       " 'niece': 4,\n",
       " 'nephew': 4,\n",
       " 'cousin': 4,\n",
       " 'family': 8,\n",
       " 'advice': 0,\n",
       " 'affirmation': 5,\n",
       " 'agreement': 1,\n",
       " 'support': 1,\n",
       " 'apology': 2,\n",
       " 'argument': 1,\n",
       " 'encouragement': 4,\n",
       " 'reassurance': 1,\n",
       " 'attack': 6,\n",
       " 'verbal': 0,\n",
       " 'bias': 5,\n",
       " 'bully': 2,\n",
       " 'call': 1,\n",
       " 'phone': 7,\n",
       " 'chat': 7,\n",
       " 'collaboration': 0,\n",
       " 'comfort': 2,\n",
       " 'compassion': 2,\n",
       " 'compromise': 1,\n",
       " 'computer': 0,\n",
       " 'communication': 5,\n",
       " 'tool': 5,\n",
       " 'condemn': 1,\n",
       " 'condescension': 2,\n",
       " 'with': 1,\n",
       " 'others': 1,\n",
       " 'confrontation': 2,\n",
       " 'conversation': 0,\n",
       " 'discussion': 5,\n",
       " 'cooperation': 5,\n",
       " 'kindness': 2,\n",
       " 'debate': 5,\n",
       " 'dispute': 1,\n",
       " 'debunk': 2,\n",
       " 'demonization': 2,\n",
       " 'online': 0,\n",
       " 'internet': 0,\n",
       " 'trust': 1,\n",
       " 'pity': 2,\n",
       " 'hostility': 1,\n",
       " 'another': 2,\n",
       " 'person': 1,\n",
       " 'control': 1,\n",
       " 'forgiveness': 1,\n",
       " 'fight': 6,\n",
       " 'argue': 5,\n",
       " 'secrecy': 1,\n",
       " 'separation': 1,\n",
       " 'listen': 2,\n",
       " 'dialogue': 5,\n",
       " 'share': 5,\n",
       " 'acceptance': 1,\n",
       " 'between': 5,\n",
       " 'connection': 5,\n",
       " 'judgmental': 2,\n",
       " 'prejudice': 1,\n",
       " 'disobedience': 5,\n",
       " 'help': 1,\n",
       " 'consensus': 5,\n",
       " 'respect': 1,\n",
       " 'response': 5,\n",
       " 'disown': 4,\n",
       " 'rejection': 1,\n",
       " 'rude': 2,\n",
       " 'disrespect': 2,\n",
       " 'outreach': 6,\n",
       " 'judge': 1,\n",
       " 'form': 5,\n",
       " 'about': 5,\n",
       " 'coerce': 1,\n",
       " 'beneficence': 1,\n",
       " 'abuse': 8,\n",
       " 'atrocity': 2,\n",
       " 'barbarity': 2,\n",
       " 'genocide': 5,\n",
       " 'bomb': 6,\n",
       " 'cruelty': 2,\n",
       " 'danger': 2,\n",
       " 'execution': 2,\n",
       " 'murder': 2,\n",
       " 'assassination': 2,\n",
       " 'shoot': 7,\n",
       " 'weapon': 2,\n",
       " 'bullets': 7,\n",
       " 'harassment': 1,\n",
       " 'incest': 2,\n",
       " 'rape': 8,\n",
       " 'killer': 2,\n",
       " 'violence': 5,\n",
       " 'terrorism': 5,\n",
       " 'harm': 1,\n",
       " 'providers': 8,\n",
       " 'fetuses': 8,\n",
       " 'slaughter': 2,\n",
       " 'dangerous': 2,\n",
       " 'threat': 1,\n",
       " 'exploitation': 5,\n",
       " 'base': 5,\n",
       " 'anniversary': 6,\n",
       " 'marriage': 1,\n",
       " 'couple': 8,\n",
       " 'partner': 8,\n",
       " 'single': 1,\n",
       " 'marital': 8,\n",
       " 'status': 5,\n",
       " 'unmarried': 8,\n",
       " 'marry': 6,\n",
       " 'husband': 4,\n",
       " 'wife': 4,\n",
       " 'spouse': 4,\n",
       " 'unwed': 8,\n",
       " 'boyfriend': 4,\n",
       " 'girlfriend': 4,\n",
       " 'romantic': 2,\n",
       " 'break': 2,\n",
       " 'accompaniment': 0,\n",
       " 'accompany': 0,\n",
       " 'ally': 6,\n",
       " 'solidarity': 5,\n",
       " 'camaraderie': 0,\n",
       " 'sisterhood': 0,\n",
       " 'comrade': 4,\n",
       " 'friendship': 4,\n",
       " 'escort': 7,\n",
       " 'friend': 4,\n",
       " 'accessibility': 1,\n",
       " 'autonomy': 5,\n",
       " 'inaccessible': 1,\n",
       " 'discrimination': 1,\n",
       " 'empowerment': 5,\n",
       " 'equality': 5,\n",
       " 'equity': 5,\n",
       " 'essential': 5,\n",
       " 'freedom': 1,\n",
       " 'humanitarian': 6,\n",
       " 'liberation': 5,\n",
       " 'legal': 1,\n",
       " 'concept': 5,\n",
       " 'reproductive': 5,\n",
       " 'justice': 1,\n",
       " 'srhr': 1,\n",
       " 'human': 5,\n",
       " 'empower': 1,\n",
       " 'independence': 6,\n",
       " 'liberate': 1,\n",
       " 'unavailable': 8,\n",
       " 'entitlement': 1,\n",
       " 'injustice': 2,\n",
       " 'rule': 1,\n",
       " 'case': 1,\n",
       " 'court': 1,\n",
       " 'supreme': 1,\n",
       " 'wade': 4,\n",
       " 'courtroom': 7,\n",
       " 'official': 6,\n",
       " 'lawsuit': 6,\n",
       " 'litigation': 1,\n",
       " 'evidence': 5,\n",
       " 'incarceration': 8,\n",
       " 'punitive': 1,\n",
       " 'liability': 1,\n",
       " 'amendment': 1,\n",
       " 'propose': 1,\n",
       " 'legislation': 1,\n",
       " 'buffer': 6,\n",
       " 'zone': 6,\n",
       " 'personhood': 5,\n",
       " 'fetal': 8,\n",
       " 'partial': 1,\n",
       " 'birth': 8,\n",
       " 'period': 5,\n",
       " 'mandate': 1,\n",
       " 'restriction': 1,\n",
       " 'regulation': 1,\n",
       " 'restrictive': 1,\n",
       " 'laws': 1,\n",
       " 'liberal': 1,\n",
       " 'prohibition': 1,\n",
       " 'accusation': 2,\n",
       " 'arrest': 6,\n",
       " 'criminal': 1,\n",
       " 'prosecution': 1,\n",
       " 'jail': 6,\n",
       " 'prison': 6,\n",
       " 'detention': 6,\n",
       " 'imprison': 6,\n",
       " 'criminalization': 8,\n",
       " 'penalization': 8,\n",
       " 'penalty': 1,\n",
       " 'decriminalization': 8,\n",
       " 'liberalization': 1,\n",
       " 'illegal': 6,\n",
       " 'penal': 1,\n",
       " 'system': 1,\n",
       " 'punishment': 1,\n",
       " 'police': 6,\n",
       " 'crime': 8,\n",
       " 'code': 1,\n",
       " 'common': 5,\n",
       " 'maternal': 8,\n",
       " 'mortality': 8,\n",
       " 'research': 5,\n",
       " 'advance': 5,\n",
       " 'medical': 8,\n",
       " 'achievement': 5,\n",
       " 'clinical': 8,\n",
       " 'test': 8,\n",
       " 'sterile': 8,\n",
       " 'equipment': 7,\n",
       " 'larc': 8,\n",
       " 'needle': 7,\n",
       " 'condoms': 8,\n",
       " 'laminaria': 8,\n",
       " 'instrument': 1,\n",
       " 'scissor': 7,\n",
       " 'cancer': 8,\n",
       " 'complications': 8,\n",
       " 'condition': 5,\n",
       " 'emergency': 6,\n",
       " 'relate': 5,\n",
       " 'risk': 8,\n",
       " 'death': 2,\n",
       " 'shock': 2,\n",
       " 'heal': 8,\n",
       " 'unsafe': 8,\n",
       " 'coat': 7,\n",
       " 'back': 7,\n",
       " 'alley': 7,\n",
       " 'backstreet': 8,\n",
       " 'zika': 8,\n",
       " 'rupture': 5,\n",
       " 'hemorrhage': 8,\n",
       " 'have': 1,\n",
       " 'quality': 8,\n",
       " 'bloody': 2,\n",
       " 'success': 1,\n",
       " 'safe': 1,\n",
       " 'fetus': 8,\n",
       " 'sepsis': 8,\n",
       " 'recovery': 8,\n",
       " 'stick': 7,\n",
       " 'hysterectomy': 8,\n",
       " 'survival': 8,\n",
       " 'reduction': 8,\n",
       " 'disease': 8,\n",
       " 'abortifacient': 0,\n",
       " 'adherence': 1,\n",
       " 'regimen': 8,\n",
       " 'administration': 6,\n",
       " 'medicine': 8,\n",
       " 'contraception': 8,\n",
       " 'pill': 8,\n",
       " 'hormonal': 8,\n",
       " 'contraceptive': 8,\n",
       " 'implant': 8,\n",
       " 'mifepristone': 8,\n",
       " 'misoprostol': 8,\n",
       " 'pills': 8,\n",
       " 'antibiotics': 8,\n",
       " 'sedative': 8,\n",
       " 'method': 5,\n",
       " 'tablets': 7,\n",
       " 'herbs': 8,\n",
       " 'comprehensive': 5,\n",
       " 'confidentiality': 1,\n",
       " 'consent': 1,\n",
       " 'inform': 5,\n",
       " 'consultation': 6,\n",
       " 'counsel': 8,\n",
       " 'examination': 5,\n",
       " 'ultrasound': 8,\n",
       " 'infanticide': 8,\n",
       " 'curettage': 8,\n",
       " 'dilatation': 8,\n",
       " 'dilation': 8,\n",
       " 'evacuation': 6,\n",
       " 'surgery': 8,\n",
       " 'selection': 8,\n",
       " 'termination': 8,\n",
       " 'vacuum': 8,\n",
       " 'extraction': 8,\n",
       " 'postabortion': 8,\n",
       " 'bleed': 7,\n",
       " 'follow': 0,\n",
       " 'interruption': 8,\n",
       " 'surgical': 8,\n",
       " 'block': 7,\n",
       " 'cervical': 8,\n",
       " 'prim': 1,\n",
       " 'exam': 8,\n",
       " 'remove': 1,\n",
       " 'appointment': 6,\n",
       " 'concentrate': 5,\n",
       " 'abnormality': 8,\n",
       " 'biology': 5,\n",
       " 'childbirth': 8,\n",
       " 'cord': 8,\n",
       " 'umbilical': 7,\n",
       " 'conception': 5,\n",
       " 'fertility': 8,\n",
       " 'contraction': 6,\n",
       " 'uterine': 8,\n",
       " 'delivery': 8,\n",
       " 'date': 0,\n",
       " 'beat': 7,\n",
       " 'miscarriage': 8,\n",
       " 'second': 5,\n",
       " 'trimester': 8,\n",
       " 'first': 0,\n",
       " 'third': 6,\n",
       " 'anomaly': 2,\n",
       " 'menstruation': 8,\n",
       " 'embryo': 8,\n",
       " 'placenta': 8,\n",
       " 'products': 8,\n",
       " 'foetus': 8,\n",
       " 'menstrual': 8,\n",
       " 'failure': 1,\n",
       " 'infertility': 8,\n",
       " 'reproduction': 5,\n",
       " 'gestation': 8,\n",
       " 'antenatal': 8,\n",
       " 'activist': 4,\n",
       " 'activism': 5,\n",
       " 'advocate': 1,\n",
       " 'action': 1,\n",
       " 'anti': 1,\n",
       " 'against': 1,\n",
       " 'voice': 0,\n",
       " 'movement': 5,\n",
       " 'progress': 5,\n",
       " 'campaign': 6,\n",
       " 'advocacy': 5,\n",
       " 'canvas': 0,\n",
       " 'champion': 1,\n",
       " 'change': 5,\n",
       " 'coalition': 6,\n",
       " 'collective': 5,\n",
       " 'commitment': 5,\n",
       " 'defend': 1,\n",
       " 'demand': 1,\n",
       " 'demonstration': 6,\n",
       " 'protest': 6,\n",
       " 'feminism': 5,\n",
       " 'heroes': 2,\n",
       " 'activity': 5,\n",
       " 'mobilization': 5,\n",
       " 'network': 5,\n",
       " 'opposition': 1,\n",
       " 'protester': 7,\n",
       " 'picket': 6,\n",
       " 'political': 5,\n",
       " 'september': 6,\n",
       " 'march': 6,\n",
       " 'speak': 2,\n",
       " 'event': 0,\n",
       " 'feminist': 5,\n",
       " 'resistance': 5,\n",
       " 'strategy': 5,\n",
       " 'alliance': 6,\n",
       " 'revolution': 5,\n",
       " 'grassroots': 5,\n",
       " 'progressive': 5,\n",
       " 'candidate': 6,\n",
       " 'conservative': 1,\n",
       " 'leave': 2,\n",
       " 'wing': 6,\n",
       " 'maker': 4,\n",
       " 'politician': 4,\n",
       " 'controversy': 2,\n",
       " 'propaganda': 0,\n",
       " 'polarize': 1,\n",
       " 'constitution': 1,\n",
       " 'policy': 5,\n",
       " 'assembly': 6,\n",
       " 'parliament': 6,\n",
       " 'congress': 6,\n",
       " 'legislature': 1,\n",
       " 'election': 6,\n",
       " 'capitalism': 5,\n",
       " 'socialism': 5,\n",
       " 'oligarchy': 1,\n",
       " 'autocracy': 6,\n",
       " 'theocracy': 1,\n",
       " 'authoritarianism': 5,\n",
       " 'dictatorship': 6,\n",
       " 'caucus': 6,\n",
       " 'colonialism': 5,\n",
       " 'state': 1,\n",
       " 'government': 1,\n",
       " 'politics': 5,\n",
       " 'vote': 1,\n",
       " 'communism': 2,\n",
       " 'aftermath': 2,\n",
       " 'after': 6,\n",
       " 'afterward': 6,\n",
       " 'backward': 2,\n",
       " 'begin': 6,\n",
       " 'brief': 0,\n",
       " 'quick': 2,\n",
       " 'past': 5,\n",
       " 'present': 5,\n",
       " 'future': 5,\n",
       " 'early': 6,\n",
       " 'delay': 8,\n",
       " 'afternoon': 7,\n",
       " 'morning': 7,\n",
       " 'even': 1,\n",
       " 'night': 7,\n",
       " 'annual': 6,\n",
       " 'centuries': 5,\n",
       " 'decades': 5,\n",
       " 'days': 6,\n",
       " 'week': 6,\n",
       " 'month': 6,\n",
       " 'year': 6,\n",
       " 'january': 6,\n",
       " 'february': 6,\n",
       " 'april': 6,\n",
       " 'june': 6,\n",
       " 'july': 6,\n",
       " 'august': 6,\n",
       " 'october': 6,\n",
       " 'november': 6,\n",
       " 'december': 6,\n",
       " 'monday': 7,\n",
       " 'tuesday': 7,\n",
       " 'wednesday': 7,\n",
       " 'thursday': 6,\n",
       " 'friday': 6,\n",
       " 'saturday': 7,\n",
       " 'sunday': 7,\n",
       " 'winter': 7,\n",
       " 'spring': 6,\n",
       " 'season': 7,\n",
       " 'summer': 6,\n",
       " 'autumn': 7,\n",
       " 'article': 0,\n",
       " 'personality': 5,\n",
       " 'psychology': 5,\n",
       " 'benevolent': 1,\n",
       " 'attitudes': 5,\n",
       " 'toward': 1,\n",
       " 'bulletin': 0,\n",
       " 'reprint': 0,\n",
       " 'multi': 5,\n",
       " 'study': 5,\n",
       " 'longitudinal': 8,\n",
       " 'huang': 8,\n",
       " 'paul': 4,\n",
       " 'davies': 4,\n",
       " 'chris': 4,\n",
       " 'sibley': 4,\n",
       " 'danny': 4,\n",
       " 'osborne': 4,\n",
       " 'although': 1,\n",
       " 'ideology': 5,\n",
       " 'that': 1,\n",
       " 'highly': 5,\n",
       " 'revere': 4,\n",
       " 'conform': 1,\n",
       " 'traditional': 5,\n",
       " 'cloak': 2,\n",
       " 'superficially': 2,\n",
       " 'tone': 0,\n",
       " 'place': 5,\n",
       " 'upon': 1,\n",
       " 'pedestal': 7,\n",
       " 'inherently': 1,\n",
       " 'accordingly': 5,\n",
       " 'because': 1,\n",
       " 'paternalistic': 1,\n",
       " 'beliefs': 5,\n",
       " 'associate': 8,\n",
       " 'idealization': 2,\n",
       " 'roles': 5,\n",
       " 'which': 5,\n",
       " 'include': 5,\n",
       " 'should': 1,\n",
       " 'predict': 1,\n",
       " 'data': 8,\n",
       " 'from': 6,\n",
       " 'nationwide': 6,\n",
       " 'panel': 0,\n",
       " 'hostile': 1,\n",
       " 'cross': 0,\n",
       " 'effect': 5,\n",
       " 'both': 5,\n",
       " 'elective': 6,\n",
       " 'traumatic': 2,\n",
       " 'extend': 5,\n",
       " 'these': 5,\n",
       " 'find': 1,\n",
       " 'relationship': 5,\n",
       " 'fully': 5,\n",
       " 'mediate': 5,\n",
       " ...}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Cluster #0  Cluster #1    Cluster #2      Cluster #3 Cluster #4  \\\n",
      "1          https     justify          feel      principios     tobias   \n",
      "2          texts      should       torment          tenido    spencer   \n",
      "3         format     require      laughter    relacionadas   espacios   \n",
      "4         poetry     enforce       terrify         abortos      heidi   \n",
      "5         visual       limit         scary          nuevas     nephew   \n",
      "6           film     protect    ridiculous          adems     joanna   \n",
      "7     multimedia   undermine         agony          siendo    ampliar   \n",
      "8          zines        they      frighten       comunidad      annie   \n",
      "9          audio        harm       sadness          tienen      reeve   \n",
      "10       graphic    coercive        sorrow          grupos    actress   \n",
      "11    commentary       allow         vomit            cmo      meyer   \n",
      "12          text   therefore          love       continuar  catherine   \n",
      "13      humorous     morally          weep         avances     cousin   \n",
      "14          book   necessary  helplessness           estos      brien   \n",
      "15    nonfiction        must       foolish         estigma    marlene   \n",
      "16         print        rule      terrible          nuevos      norma   \n",
      "17  bibliography  legitimate         choke          haban   costello   \n",
      "18       compile        such       anguish  representacin      studi   \n",
      "19    transcribe  government      darkness          cuenta   mitchell   \n",
      "20     postcards      ensure       tremble         estaban       andy   \n",
      "\n",
      "      Cluster #5   Cluster #6  Cluster #7     Cluster #8  \n",
      "1     understand     december      wrists   mifepristone  \n",
      "2         social         june      pillow        urinary  \n",
      "3       concepts      million      sweaty   progesterone  \n",
      "4        context      burkina       towel   preeclampsia  \n",
      "5       cultural         port       cream      infection  \n",
      "6         nature      october    backpack        hormone  \n",
      "7       approach      village   fireplace    misoprostol  \n",
      "8       practice  headquarter       scent        uterine  \n",
      "9    theoretical         july      yellow    respiratory  \n",
      "10     structure     northern       spray       diarrhea  \n",
      "11     dimension         faso  sunglasses  abnormalities  \n",
      "12     framework        march        pant        bladder  \n",
      "13     discourse    provinces       crawl     medication  \n",
      "14      analysis     tanzania     cushion         dosage  \n",
      "15    particular       deport        drip          liver  \n",
      "16       process    nationals        shoe     infections  \n",
      "17      theories      crdoba    sunlight       surgical  \n",
      "18  perspectives      january      shovel    haemorrhage  \n",
      "19         ideas        april       sweat  complications  \n",
      "20     political     santiago  windshield       diabetes  \n"
     ]
    }
   ],
   "source": [
    "top_words,tree = get_top_words(combined_vocab, 20, centers, combined_array);\n",
    "print(top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sagemaker deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_client = boto3.client('s3')\n",
    "bucket='inroads-test-bucket1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '290', '291', '292', '293', '294', '295', '296', '297', '298', '299'],\n",
       "      dtype='object', length=300)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_vectors_df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = old_array.astype('float32')\n",
    "new_data = combined_array.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import KMeans\n",
    "\n",
    "num_clusters = 9\n",
    "kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type='ml.c4.xlarge',\n",
    "                output_path='s3://'+ bucket +'/kmeans/',              \n",
    "                k=num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-20 23:21:41 Starting - Starting the training job...\n",
      "2020-08-20 23:21:45 Starting - Launching requested ML instances.........\n",
      "2020-08-20 23:23:24 Starting - Preparing the instances for training......\n",
      "2020-08-20 23:24:40 Downloading - Downloading input data...\n",
      "2020-08-20 23:25:02 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'300', u'k': u'9', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'300', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'9', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 WARNING 140513672755008] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Using default worker.\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Create Store: local\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] nvidia-smi took: 0.0251779556274 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'300', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'9', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 INFO 140513672755008] number of center slices 1\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:25 WARNING 140513672755008] Batch size 5000 is bigger than the first batch data. Effective batch size used to initialize is 941\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 941, \"sum\": 941.0, \"min\": 941}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 941, \"sum\": 941.0, \"min\": 941}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 941, \"sum\": 941.0, \"min\": 941}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1597965925.976332, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1597965925.976297}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-08-20 23:25:25.976] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 43, \"num_examples\": 1, \"num_bytes\": 1155548}\u001b[0m\n",
      "\u001b[34m[2020-08-20 23:25:26.049] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 72, \"num_examples\": 1, \"num_bytes\": 1155548}\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] processed a total of 941 examples\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 941, \"sum\": 941.0, \"min\": 941}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Total Records Seen\": {\"count\": 1, \"max\": 1882, \"sum\": 1882.0, \"min\": 1882}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 941, \"sum\": 941.0, \"min\": 941}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1597965926.050438, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1597965925.976637}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] #throughput_metric: host=algo-1, train throughput=12725.0102011 records/second\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 WARNING 140513672755008] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] shrinking 90 centers into 9\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #0. Current mean square distance 0.181491\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #1. Current mean square distance 0.186474\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #2. Current mean square distance 0.182958\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #3. Current mean square distance 0.183389\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #4. Current mean square distance 0.184829\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #5. Current mean square distance 0.184260\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #6. Current mean square distance 0.180957\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #7. Current mean square distance 0.179410\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #8. Current mean square distance 0.182407\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] local kmeans attempt #9. Current mean square distance 0.184354\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] finished shrinking process. Mean Square Distance = 0\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] #quality_metric: host=algo-1, train msd <loss>=0.179410278797\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] compute all data-center distances: inner product took: 47.9850%, (0.038182 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] batch data loading with context took: 12.4769%, (0.009928 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] compute all data-center distances: point norm took: 10.4685%, (0.008330 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] collect from kv store took: 9.0270%, (0.007183 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] splitting centers key-value pair took: 8.8085%, (0.007009 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] gradient: one_hot took: 4.0076%, (0.003189 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] predict compute msd took: 3.3667%, (0.002679 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] gradient: cluster center took: 1.5119%, (0.001203 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] gradient: cluster size  took: 0.9891%, (0.000787 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] update state and report convergance took: 0.5744%, (0.000457 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] compute all data-center distances: center norm took: 0.4536%, (0.000361 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] update set-up time took: 0.2766%, (0.000220 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] predict minus dist took: 0.0542%, (0.000043 secs)\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] TOTAL took: 0.0795707702637\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 293.0140495300293, \"sum\": 293.0140495300293, \"min\": 293.0140495300293}, \"initialize.time\": {\"count\": 1, \"max\": 36.41104698181152, \"sum\": 36.41104698181152, \"min\": 36.41104698181152}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.15497207641601562, \"sum\": 0.15497207641601562, \"min\": 0.15497207641601562}, \"update.time\": {\"count\": 1, \"max\": 73.60291481018066, \"sum\": 73.60291481018066, \"min\": 73.60291481018066}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 1.4188289642333984, \"sum\": 1.4188289642333984, \"min\": 1.4188289642333984}, \"_shrink.time\": {\"count\": 1, \"max\": 291.0130023956299, \"sum\": 291.0130023956299, \"min\": 291.0130023956299}}, \"EndTime\": 1597965926.345553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1597965925.932587}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/20/2020 23:25:26 INFO 140513672755008] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 479.8929691314697, \"sum\": 479.8929691314697, \"min\": 479.8929691314697}, \"setuptime\": {\"count\": 1, \"max\": 14.183998107910156, \"sum\": 14.183998107910156, \"min\": 14.183998107910156}}, \"EndTime\": 1597965926.346254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1597965926.345658}\n",
      "\u001b[0m\n",
      "\n",
      "2020-08-20 23:25:35 Uploading - Uploading generated training model\n",
      "2020-08-20 23:25:35 Completed - Training job completed\n",
      "Training seconds: 55\n",
      "Billable seconds: 55\n",
      "CPU times: user 598 ms, sys: 28 ms, total: 626 ms\n",
      "Wall time: 4min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans.fit(kmeans.record_set(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------!CPU times: user 296 ms, sys: 15.7 ms, total: 312 ms\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1, \n",
    "                                 instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 ms, sys: 26 s, total: 25.7 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result=kmeans_predictor.predict(new_data[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = [r.label['closest_cluster'].float32_tensor.values[0] for r in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    35\n",
       "5.0    26\n",
       "4.0    13\n",
       "2.0    10\n",
       "6.0     9\n",
       "3.0     4\n",
       "8.0     2\n",
       "7.0     1\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cluster_labels)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "ax=plt.subplots(figsize=(6,3))\n",
    "ax=sns.distplot(cluster_labels, kde=False)\n",
    "title=\"Histogram of Cluster Counts\"\n",
    "ax.set_title(title, fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "job_name = kmeans.latest_training_job.name\n",
    "model_key = \"kmeans/\" + job_name + \"/output/model.tar.gz\"\n",
    "\n",
    "boto3.resource('s3').Bucket(bucket).download_file(model_key, 'model.tar.gz')\n",
    "os.system('tar -zxvf model.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mxnet in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.6.0)\n",
      "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (1.18.1)\n",
      "Requirement already satisfied: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from mxnet) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (1.25.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2.9)\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install mxnet\n",
    "import mxnet as mx\n",
    "\n",
    "Kmeans_model_params = mx.ndarray.load('model_algo-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## REMEMBER TO CLOSE SESSION!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker.Session().delete_endpoint(kmeans_predictor.endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
